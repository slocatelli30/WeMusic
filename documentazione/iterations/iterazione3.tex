\section{Introduzione}
Nella terza iterazione è stato approfondito e implementato l'algoritmo portante del sistema: l'algoritmo di Discover permette di ``Scoprire" nuova 
musica e nuovi utenti in base alle preferenze dell'utente.


\section{Descrizione dell'algoritmo}
L'algoritmo di Discover è stato ideato per offrire all'utente un'esperienza completa di riproduzione e scoperta di nuova musica, unendo a ciò la 
componente social: in questo modo si permette all'utente di conoscere nuove persone che condividono con lui i propri gusti musicali. 

Questo tipo di algoritmo 
tiene traccia dei generi preferiti dell'utente e lo utilizza per suggerire musica simile, ma non solo: allo stesso modo riesce a suggerire 
una lista di utenti che hanno gusti simili all'utente loggato, in modo da poterli aggiungere alla propria lista di amici.  

Le variabili e i fattori tenuti in considerazione per lo sviluppon dell'algoritmo di Discover sono i seguenti: 
\begin{itemize}
    \item Il genere favorito dell'utente, ottenuto da un'analisi dei suoi brani preferiti;
    \item L'età dell'utente;
    \item Il sesso dell'utente.
\end{itemize}


\newpage
\section{Funzionamento dell'algoritmo}
Il funzionamento dell'algoritmo si basa su una previsione Machine Learning, tramite la libreria \textbf{Pandas} di Python;
il nome fa riferimento sia a ``Panel Data" che ``Python Data Analysis", infatti è una libreria molto utilizzata per lavorare 
con dataset: tramite le sue molteplici funzioni consente di analizzare, pulire, esplorare e manipolare i dati, definendo 
conclusioni basate su teorie statistiche. 

Come anticipato, in base al genere preferito dell'utente, il suo sesso e la sua età, l'algoritmo suggerisce dei brani ricavandoli 
da un dataset, filtrandoli secondo le variabili sopracitate. Al termine dell'esecuzione l'algoritmo mostrerà un elenco di brani e amici suggeriti.

Gli step di funzionamento dell'algoritmo possono essere così riassunti: 
\begin{itemize}
    \item Inizialmente, viene creato un oggetto account contenente le informazioni relative all'account dell'utente loggato, che ci serviranno in seguito; 
    viene passato il parametro \textbf{request} che è quello che contiene le informazioni di interesse, ovvero l'età e il sesso (1=maschio, 0=femmina). 
    In seguito viene utilizzato un training set (\textbf{utenti.csv}) sul quale allenare la stima, contenente le informazioni degli utenti 
    necessarie per estrapolare le variabili: quelle di input includono il sesso e l'età dell'utente, quella di output contiene solo 
    il genere preferito (ciò che suggerirà l'algoritmo). 

    \item Dopo aver creato queste due tabelle viene istanziato il modello previsionale tramite il comando \textbf{DecisionTreeClassifier}, un comando 
    della libreria Pandas che permette, dandogli in input le variabili considerate, di fittare il modello che le lega. 
    
    \item Viene quindi fittato il modello tramite il comando \textbf{modello.fit(...)}, che si allenerà sulle variabili scelte (età e sesso), per restituire 
    il risultato (genere preferito). 

    \item In seguito verrà effettuata la predizione inserendo le informazioni relative all'utente loggato tramite la funzione \textbf{modello.predict}, ed 
    infine viene memorizzata la previsione relativa solo alla variabile di genere musicale. 
    
\end{itemize}


\newpage
\subsection{Discover: Suggerimento brano}
Nella parte successiva dell'algoritmo Discover si effettua un semplice filtro su tutte le canzoni presenti nel database del sistema e vengono
 selezionate solo quelle che rispettano il genere target restituito dall'algoritmo Discover; vengono in seguito salvate in una 
 lista e proposte all'utente, che sarà in grado di navigare e selezionare quale scaricare o aggiungere ai preferiti o ad una playlist. 

\subsection{Discover: Suggerimento amici}
Nell'ultima parte dell'algoritmo Discover viene seguito un processo più meccanico: facendo ancora riferimento al genere target 
individuato nella parte iniziale dell'algoritmo, viene estrapolata una lista di amici suggeriti per l'utente. 

Inizialmente viene creata una lista amici vuota, vengono salvate le informazioni relative dell'utente loggato, vengono quindi 
selezionati tutti gli utenti presenti nella lista amici (in modo da escluderli in seguito nell'algoritmo).
Dopo aver creato una lista degli identificativi, tramite un ciclo for each vengono selezionati gli utenti nel database 
sfogliando per ognuno le canzoni preferite, al fine di salvare il genere di ogni canzone in una variabile y.

Condizione per rientrare negli utenti suggeriti:
\begin{itemize}
    \item L'utente analizzato (nel database) non deve essere l'utente loggato, ovvero devono avere id diversi;
    \item L'utente analizzato (nel database) non deve essere amico dell'utente loggato, ovvero il suo id non deve essere presente 
    nella lista amici;
    \item All'utente analizzato (nel database) deve piacere almeno una canzone che abbia lo stesso genere target dell'algoritmo.

\end{itemize}

Nel context viene poi passata la lista creata con gli utenti selezionati dal database, in modo da permettere all'utente di poter
navigare fra gli utenti ed, eventualmente, aggiungerli fra gli amici. 




\newpage

\section{Studio della complessità}

% codice 1
\subsection{Pseudocodice}

\vspace{0.5cm}

\subparagraph{Pseudocodice - Parte I}
Pseudocodice della prima parte dell'algoritmo, relativa all'inizializzazione 
e all'individuazione del genere target. 
\begin{figure}[H]
    \centering
    \begin{center}
    \includegraphics[scale=0.5]{images/alg1_v2.jpg}
    \end{center}
    \caption{Codice (parte I)}
    \label{fig-codice1}
\end{figure}

% pseudocodice 1
%\include{./algorithm/pseudocodice1.tex}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{images/pseudocodice1.jpg}
    \caption{Pseudocodice (parte I)}
    \label{fig-pseudocodice1}
\end{figure}
\vspace{1.5cm}

\newpage

\subparagraph{Pseudocodice - Parte II}
%codice parte 2
Pseudocodice della seconda parte dell'algoritmo, relativa al suggerimento 
dei brani in base al genere target.
%\begin{figure}[H]
%    \centering
%    \includegraphics[scale=0.5]{images/alg2_v2.jpg}
%    \caption{Codice (parte II)}
%    \label{fig-codice2}
%\end{figure}

% pseudocodice 2
%\include{./algorithm/pseudocodice2.tex}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{images/pseudocodice2.jpg}
    \caption{Pseudocodice (parte II)}
    \label{fig-pseudocodice2}
\end{figure}
\vspace{1.5cm}




\newpage

% codice 3
\subparagraph{Pseudocodice - Parte III}
Pseudocodice della terza parte dell'algoritmo, quella relativa al
suggerimento di utenti con gusti simili. 
%\begin{figure}[H]
%    \centering
%    \includegraphics[scale=0.7]{images/alg3_v2.jpg}
%%    \caption{Codice (Parte III)}
%    \label{fig-codice3}
%\end{figure}


% pseudocodice 3
%\include{./algorithm/pseudocodice3.tex}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{images/pseudocodice3.jpg}
    \caption{Pseudocodice (parte III)}
    \label{fig-pseudocodice3}
\end{figure}
\vspace{1.5cm}



\newpage
% codice 4

\subparagraph{Pseudocodice - Parte IV}
Pseudocodice dell'ultima parte dell'algoritmo.  
%\begin{figure}[H]
%    \centering
%    \includegraphics[scale=0.7]{images/alg4_v2.jpg}
%    \caption{Codice (parte IV)}
%    \label{fig-codice4}
%\end{figure}
%\vspace{0.5cm}

% pseudocodice 4
%\include{algorithm/pseudocodice4.tex}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{images/pseudocodice4.jpg}
    \caption{Pseudocodice (parte IV)}
    \label{fig-pseudocodice4}
\end{figure}
\vspace{1.5cm}





\newpage
\subsection{Analisi della complessità}
Per valutare la complessità temporale dell'algoritmo, vengono esaminate le operazioni principali che 
vengono eseguite e e viene analizzato come queste operazioni dipendono dalla dimensione dell'input. 
Di seguito viene fornita una stima approssimativa della complessità temporale per ogni parte dell'algoritmo:

\begin{itemize}
    \item \textbf{Lettura del file CSV:} La lettura del file CSV tramite la funzione $read\_csv$ ha una 
    complessità temporale che dipende dalla dimensione del file, nello specifico dal numero di righe e colonne del file.
    Supponiamo che ci siano n righe e m colonne nel file. La lettura del file richiede un'operazione 
    per ogni cella nel file, di conseguenza la complessità è dell'ordine di ${O(n*m)}$.
    % sono 21 righe e 3 colonne, quindi può essere considerata costante O(1)
    \item \textbf{Creazione e addestramento del modello di classificazione:} La creazione del modello 
    \textit{DecisionTreeClassifier} e l'addestramento del modello tramite il metodo \textit{fit} dipendono dal numero di 
    caratteristiche e dal numero di esempi nel set di dati. Se denotiamo con p il numero di istanze (quindi n, le righe del file csv) 
    e con q il numero di attributi (m, il numero di colonne), allora la complessità temporale può essere approssimata a $O(p * q log(p))$, 
    poiché la costruzione di un albero decisionale richiede operazioni che dipendono da entrambi i valori.
    % sono 21 istanze e 3 colonne, quindi può essere approssimato a O(1) costante
    \item \textbf{Previsione dei generi musicali:} La previsione dei generi musicali per 
    l'utente corrente 
    utilizzando il modello addestrato ha una complessità temporale di $O(1)$, poiché si 
    tratta di un singolo esempio (operazione costante).
    \item \textbf{Filtraggio dei brani musicali:} Per ogni brano che piace all'utente corrente, viene estratto il relativo
     ID e memorizzato in una lista. Questa operazione richiede un'iterazione su tutti i $s$ brani preferiti, quindi la 
     complessità è $O(s)$.
     Il filtro dei brani musicali nel database attraverso la chiamata 
    a \textit{Song.objects.filter} può dipendere dal numero di brani nel database e dalla complessità della query. 
    Questa operazione ha una complessità temporale dell'ordine di $O(s)$, dove s rappresenta il 
    numero di brani che soddisfano i criteri di filtro.
    \item \textbf{Creazione della lista dei brani suggeriti:} Per ogni brano del training set con il genere musicale dedotto
    dall'algoritmo, viene verificato se l'ID del brano non è presente nella lista dei brani preferiti dall'utente corrente. 
    Poiché questa operazione richiede l'iterazione su tutti i z brani nel training set, la complessità è $O(z)$.
    \item \textbf{Ricerca degli amici suggeriti:} La ricerca degli amici suggeriti coinvolge \textit{due cicli for nidificati}. 
    Supponendo che ci siano \textit{x} utenti nel database e \textit{y} canzoni preferite per ogni utente, la complessità temporale di questa
    parte dell'algoritmo può essere approssimata a $O(x * y)$.
    \item \textbf{Creazione del contesto:} La creazione del contesto finale ha una complessità temporale trascurabile, 
    poiché coinvolge solo l'assegnazione di variabili.
\end{itemize}
Quindi, sommando tutte queste parti, possiamo dire che la complessità temporale complessiva dell'algoritmo è approssimativamente:

\boldmath
\begin{center}
    
    $O(n * m) + O(n * m log(m)) + O(s) + O(1)$
   
\end{center}
\unboldmath


\subparagraph{Analisi complessità di \textit{DecisionTreeClassifier}}
Il DecisionTreeClassifier fa parte di una libreria Python per il Machine Learning.
 L'addestramento di un albero decisionale utilizzando DecisionTreeClassifier si basa 
 su una serie di divisioni dei dati 
in base alle caratteristiche (features) dei campioni. La complessità principale 
dell'addestramento di un albero decisionale è determinata dalla fase di costruzione 
dell'albero stesso.
%Durante la costruzione dell'albero, l'algoritmo esamina tutte le possibili 
%divisioni delle caratteristiche e cerca quella che massimizza la "purezza" dei 
%sottoinsiemi risultanti. La purezza misura quanto bene un sottoinsieme è composto 
%da campioni di una sola classe. L'algoritmo valuta le divisioni utilizzando misure 
%come l'entropia o la Gini impurity.

La complessità dell'addestramento di un albero decisionale è influenzata 
principalmente da due fattori:
\begin{itemize}
    \item Il numero di campioni nel set di addestramento (n): Più campioni ci sono, 
        più operazioni di divisione e valutazione devono essere eseguite.
    \item Il numero di caratteristiche (features) dei campioni nel set di addestramento (m): 
        Più caratteristiche ci sono, più divisioni devono essere valutate.


\end{itemize}
Quindi, in generale, la complessità dell'addestramento di un albero decisionale 
con il DecisionTreeClassifier è approssimativamente $O(n * m * log(m))$.

\vspace{0.3cm}
\subparagraph{Analisi complessità di \textit{fit}}
Il metodo fit in Pandas viene utilizzato per adattare un modello ai dati. 
Tuttavia, la complessità del comando fit dipende dall'algoritmo di apprendimento utilizzato. 
Ad esempio, si utilizza fit con un modello di regressione lineare utilizzando il metodo dei minimi quadrati, 
la complessità è $O(n * m^2)$, dove n è il numero di campioni e m è il numero di features. 


\newpage
\subsection{Flowchart dell'algoritmo}
I passi base dell'algoritmo sono i seguenti: 

